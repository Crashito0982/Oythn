import pandas as pd
from sqlConn import sqlConn

"""
Script de generación de histórico para las tablas del modelo de bóveda.

Tablas base:
  - PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_INDICE_SUCURSALES
  - PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_ATM
  - PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_LIMITES

Tablas históricas:
  - PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_INDICE_SUCURSALES_HIST
  - PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_ATM_HIST
  - PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_LIMITES_HIST

Convención histórico:
  - La tabla HIST tiene todas las columnas de la tabla base
    + ESTADO_REGISTRO (VARCHAR(20))   -> 'VIGENTE' / 'ANTERIOR'
    + OBS_CAMBIO      (VARCHAR(255))  -> descripción del cambio
    + FECHA_CAMBIO    (DATETIME)      -> cuándo se generó esa versión

  - FECHA_CREACION viene de la tabla base (vuelco).

Lógica general:
  - Primera corrida: histórico vacío -> espejo completo de la tabla base
    con ESTADO_REGISTRO = 'VIGENTE' y OBS_CAMBIO = 'Carga inicial'.

  - Corridas siguientes:
      * Altas: claves nuevas que no existen en histórico -> VIGENTE
      * Cambios: misma clave lógica pero valores distintos en otras
        columnas de negocio -> nueva fila VIGENTE con OBS_CAMBIO
        "Cambios en: ..."
      * Bajas: claves que existían en histórico y ya no están en la base
        -> nueva fila ANTWERIOR con OBS_CAMBIO "Dado de baja (...)".

  - Recalculo de ESTADO_REGISTRO:
      * Para cada clave lógica, se toma la(s) fila(s) con la mayor
        FECHA_REF (FECHA_CAMBIO o FECHA_CREACION, lo que haya).
      * Si la última versión es una baja, todas las filas de esa clave
        quedan ANTERIOR.
      * Si no es baja, todas las filas de la última versión quedan
        VIGENTE y el resto ANTERIOR.
"""

# ======================================================
# CONFIGURACIÓN GENERAL
# ======================================================

PREDEF_CONN = "AT_CMDTS"  # conexión al motor
SCHEMA = "dbo"

# Definición de cada tabla base / histórica y su clave lógica
TABLAS_BOVEDA = [
    {
        "BASE_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_INDICE_SUCURSALES",
        "HIST_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_INDICE_SUCURSALES_HIST",
        # Clave compuesta con todas las columnas de negocio
        # (mantiene todos los registros tal cual se encuentran en la base)
        "KEY_COLS": ["SUCURSALES", "INDICE", "OBS", "TRANSPORTADORA"],
        "ENTIDAD_LABEL": "sucursal excluida del modelo de bóveda",
        "BAJA_LABEL": "sucursal excluida ya no figura en la tabla base",
    },
    {
        "BASE_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_ATM",
        "HIST_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_ATM_HIST",
        # LUNO es único
        "KEY_COLS": ["LUNO"],
        "ENTIDAD_LABEL": "ATM de bóveda",
        "BAJA_LABEL": "ATM de bóveda ya no figura en tabla base",
    },
    {
        "BASE_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_LIMITES",
        "HIST_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_BOVEDA_LIMITES_HIST",
        # Clave compuesta TRANSPORTADORA + DELEGACION
        "KEY_COLS": ["TRANSPORTADORA", "DELEGACION"],
        "ENTIDAD_LABEL": "límite de bóveda",
        "BAJA_LABEL": "límite de bóveda ya no figura en tabla base",
    },
]

STATUS_COL = "ESTADO_REGISTRO"

# Columnas de la tabla base que se ignoran al comparar versiones
# (FECHA_CREACION se recalcula en cada vuelco y no debe disparar cambios)
IGNORE_DIFF_COLS = {"FECHA_CREACION"}


# ======================================================
# HELPERS GENERALES
# ======================================================


def cargar_df(conn: sqlConn, table_name: str) -> pd.DataFrame:
    """Trae una tabla completa como DataFrame usando sqlConn.descarga_tabla."""
    return conn.descarga_tabla(nombre_base=table_name, schema=SCHEMA)


def key_tuple_from_row(row: pd.Series, key_cols, suffix: str = ""):
    """Construye la clave lógica (tuple o valor simple) desde una fila."""
    if len(key_cols) == 1:
        return row.get(key_cols[0] + suffix, row.get(key_cols[0]))
    return tuple(row.get(col + suffix, row.get(col)) for col in key_cols)


def build_key_set(df: pd.DataFrame, key_cols):
    """Devuelve el conjunto de claves lógicas presentes en un DataFrame."""
    if df.empty:
        return set()

    if len(key_cols) == 1:
        return set(df[key_cols[0]].dropna().unique())

    return set(tuple(r) for r in df[key_cols].dropna().itertuples(index=False, name=None))


def detectar_cambios_generico(
    df_actual: pd.DataFrame,
    df_hist: pd.DataFrame,
    key_cols,
    status_col: str,
    ignore_diff_cols=None,
    entidad_label: str = "registro",
    baja_label: str = "registro ya no figura en tabla base",
) -> pd.DataFrame:
    """Calcula las filas nuevas que deben insertarse en la tabla histórica.

    Maneja altas, cambios, bajas y reactivaciones.
    """

    ignore_diff_cols = set(ignore_diff_cols or set())
    now_ts = pd.Timestamp.now()

    # 1) Primera corrida: histórico vacío -> espejo completo de la tabla base
    if df_hist.empty:
        df_nuevos = df_actual.copy()
        df_nuevos[status_col] = "VIGENTE"
        df_nuevos["OBS_CAMBIO"] = "Carga inicial"
        df_nuevos["FECHA_CAMBIO"] = now_ts
        return df_nuevos

    df_hist = df_hist.copy()

    # Construimos FECHA_REF para ordenar versiones (preferencia FECHA_CAMBIO)
    if "FECHA_CAMBIO" in df_hist.columns:
        df_hist["FECHA_REF"] = df_hist["FECHA_CAMBIO"]
    else:
        df_hist["FECHA_REF"] = pd.NaT

    # fallback: si no hay FECHA_CAMBIO, usamos FECHA_CREACION
    if "FECHA_CREACION" in df_hist.columns:
        mask = df_hist["FECHA_REF"].isna()
        df_hist.loc[mask, "FECHA_REF"] = df_hist.loc[mask, "FECHA_CREACION"]

    df_hist_sorted = df_hist.sort_values(list(key_cols) + ["FECHA_REF"])
    df_hist_ult = df_hist_sorted.groupby(list(key_cols), as_index=False).tail(1)

    # Merge actual vs última versión histórica
    merged = df_actual.merge(
        df_hist_ult,
        on=list(key_cols),
        how="left",
        suffixes=("_cur", "_prev"),
        indicator=True,
    )

    # Columnas de negocio a comparar (solo las de la tabla base)
    cur_cols = [c for c in merged.columns if c.endswith("_cur")]
    base_cols = []
    for c in cur_cols:
        base_name = c[:-4]
        if base_name not in ignore_diff_cols and base_name not in {
            status_col,
            "OBS_CAMBIO",
            "FECHA_CAMBIO",
        }:
            base_cols.append(base_name)

    def columnas_cambiadas(row: pd.Series):
        cambios = []
        for col in base_cols:
            col_cur = f"{col}_cur"
            col_prev = f"{col}_prev"
            val_cur = row.get(col_cur, pd.NA)
            val_prev = row.get(col_prev, pd.NA)

            if pd.isna(val_cur) and pd.isna(val_prev):
                continue
            if (pd.isna(val_cur) and not pd.isna(val_prev)) or (
                not pd.isna(val_cur) and pd.isna(val_prev)
            ):
                cambios.append(col)
            elif val_cur != val_prev:
                cambios.append(col)

        return cambios

    # IDs cuya última versión está dada de baja
    if "OBS_CAMBIO" in df_hist_ult.columns:
        mask_baja = df_hist_ult["OBS_CAMBIO"].fillna("").str.contains(
            r"^\s*Dado de baja\b", case=False, na=False, regex=True
        )
        if len(key_cols) == 1:
            ids_baja_hist = set(df_hist_ult.loc[mask_baja, key_cols[0]].unique())
        else:
            ids_baja_hist = set(
                tuple(row[col] for col in key_cols)
                for _, row in df_hist_ult.loc[mask_baja, key_cols].iterrows()
            )
    else:
        ids_baja_hist = set()

    ids_actual = build_key_set(df_actual, key_cols)
    ids_reactivados = ids_actual & ids_baja_hist

    def is_reactivacion(row: pd.Series) -> bool:
        if row["_merge"] != "both":
            return False
        key = key_tuple_from_row(row, key_cols, "")
        return key in ids_reactivados

    merged["ES_REACTIVACION"] = merged.apply(is_reactivacion, axis=1)

    filas_nuevas = []

    # 2a) Altas: claves nuevas que solo están en la tabla base
    nuevos_ids = merged[merged["_merge"] == "left_only"]
    for _, row in nuevos_ids.iterrows():
        registro = {}
        for col in df_actual.columns:
            registro[col] = row.get(col, row.get(f"{col}_cur", pd.NA))
        registro[status_col] = "VIGENTE"
        registro["OBS_CAMBIO"] = f"Alta de {entidad_label} (nuevo ID)"
        registro["FECHA_CAMBIO"] = now_ts
        filas_nuevas.append(registro)

    # 2b) Reactivaciones
    reactivados = merged[merged["ES_REACTIVACION"]].copy()
    if not reactivados.empty:
        reactivados["CAMBIOS"] = reactivados.apply(columnas_cambiadas, axis=1)
        for _, row in reactivados.iterrows():
            registro = {}
            for col in df_actual.columns:
                registro[col] = row.get(col, row.get(f"{col}_cur", pd.NA))
            cols_cambiadas = row["CAMBIOS"]
            if cols_cambiadas:
                obs = (
                    f"Reactivación de {entidad_label} (estaba dado de baja). "
                    "Cambios en: " + ", ".join(cols_cambiadas)
                )
            else:
                obs = f"Reactivación de {entidad_label} (estaba dado de baja)"
            registro[status_col] = "VIGENTE"
            registro["OBS_CAMBIO"] = obs
            registro["FECHA_CAMBIO"] = now_ts
            filas_nuevas.append(registro)

    # 2c) Cambios normales en registros existentes
    coinciden = merged[(merged["_merge"] == "both") & (~merged["ES_REACTIVACION"])].copy()
    if not coinciden.empty:
        coinciden["CAMBIOS"] = coinciden.apply(columnas_cambiadas, axis=1)
        cambiados = coinciden[coinciden["CAMBIOS"].apply(len) > 0]
        for _, row in cambiados.iterrows():
            registro = {}
            for col in df_actual.columns:
                registro[col] = row.get(col, row.get(f"{col}_cur", pd.NA))
            cols_cambiadas = row["CAMBIOS"]
            obs = "Cambios en: " + ", ".join(cols_cambiadas)
            registro[status_col] = "VIGENTE"
            registro["OBS_CAMBIO"] = obs
            registro["FECHA_CAMBIO"] = now_ts
            filas_nuevas.append(registro)

    # 2d) Bajas: claves que estaban en el histórico y ya no están en la tabla base
    if len(key_cols) == 1:
        ids_hist = set(df_hist_ult[key_cols[0]].unique())
    else:
        ids_hist = set(
            tuple(row[col] for col in key_cols)
            for _, row in df_hist_ult[key_cols].iterrows()
        )

    ids_pot_baja = ids_hist - ids_actual

    if ids_pot_baja:
        df_baja_base = df_hist_ult.copy()
        df_baja_base["ES_BAJA"] = df_baja_base["OBS_CAMBIO"].fillna("").str.contains(
            r"^\s*Dado de baja\b", case=False, na=False, regex=True
        )

        def key_in_pot(row: pd.Series) -> bool:
            if len(key_cols) == 1:
                key = row[key_cols[0]]
            else:
                key = tuple(row[col] for col in key_cols)
            return key in ids_pot_baja

        df_baja_base = df_baja_base[df_baja_base.apply(key_in_pot, axis=1)]
        df_baja_nuevos = df_baja_base[~df_baja_base["ES_BAJA"]]

        for _, row in df_baja_nuevos.iterrows():
            registro = {}
            for col in df_actual.columns:
                registro[col] = row.get(col, pd.NA)
            registro[status_col] = "ANTERIOR"
            registro["OBS_CAMBIO"] = f"Dado de baja ({baja_label})"
            registro["FECHA_CAMBIO"] = now_ts
            filas_nuevas.append(registro)

    if not filas_nuevas:
        # Nada que agregar en esta corrida
        return pd.DataFrame(columns=list(df_actual.columns) + [status_col, "OBS_CAMBIO", "FECHA_CAMBIO"])

    return pd.DataFrame(filas_nuevas)


def recalcular_estados_generico(
    df_hist_total: pd.DataFrame,
    key_cols,
    status_col: str,
) -> pd.DataFrame:
    """Recalcula ESTADO_REGISTRO sobre el histórico completo.

    - Para cada clave lógica buscamos la(s) fila(s) con la FECHA_REF máxima
      (última versión). FECHA_REF se define como FECHA_CAMBIO si existe, o
      FECHA_CREACION en su defecto.

    - Si la última versión es una baja (OBS_CAMBIO comienza con "Dado de baja"):
        => todas las filas de esa clave quedan ANTERIOR.

    - Si la última versión NO es baja:
        => todas las filas de la última versión quedan VIGENTE y el resto
           de esa clave queda ANTERIOR.

    Esto permite que, por ejemplo, en la carga inicial con duplicados, todas
    las filas de la única versión existente queden VIGENTE.
    """

    df = df_hist_total.copy()

    # 1) FECHA_REF: prioridad FECHA_CAMBIO, luego FECHA_CREACION
    if "FECHA_CAMBIO" in df.columns:
        df["FECHA_REF"] = df["FECHA_CAMBIO"]
    else:
        df["FECHA_REF"] = pd.NaT

    if "FECHA_CREACION" in df.columns:
        mask = df["FECHA_REF"].isna()
        df.loc[mask, "FECHA_REF"] = df.loc[mask, "FECHA_CREACION"]

    # Ordenamos por clave y FECHA_REF para prolijidad
    df.sort_values(list(key_cols) + ["FECHA_REF"], inplace=True)

    # FECHA_REF máxima por clave
    df["MAX_FECHA_REF"] = df.groupby(list(key_cols))["FECHA_REF"].transform("max")

    # Marca: esta fila pertenece a la "última versión" de su clave
    df["ES_ULTIMA_VERSION"] = df["FECHA_REF"] == df["MAX_FECHA_REF"]

    # Clave interna para no depender de apply con slices de columnas
    if len(key_cols) == 1:
        df["_KEY_"] = df[key_cols[0]]
    else:
        df["_KEY_"] = list(zip(*(df[col] for col in key_cols)))

    # Filas de última versión
    ultimas = df[df["ES_ULTIMA_VERSION"]].copy()
    ultimas["ES_BAJA"] = ultimas["OBS_CAMBIO"].fillna("").str.contains(
        r"^\s*Dado de baja\b", case=False, na=False, regex=True
    )

    # Claves cuya última versión es una baja
    ids_baja = set(ultimas.loc[ultimas["ES_BAJA"], "_KEY_"])

    # Por defecto, todos ANTERIOR
    df[status_col] = "ANTERIOR"

    # Filas vigentes: últimas versiones cuya clave NO está dada de baja
    mask_vig = df["ES_ULTIMA_VERSION"] & ~df["_KEY_"].isin(ids_baja)
    df.loc[mask_vig, status_col] = "VIGENTE"

    # Limpieza de columnas auxiliares
    df.drop(columns=["FECHA_REF", "MAX_FECHA_REF", "ES_ULTIMA_VERSION", "_KEY_"], inplace=True)

    return df


# ======================================================
# PROCESO POR TABLA
# ======================================================


def procesar_tabla_boveda(conn: sqlConn, cfg: dict) -> None:
    base_table = cfg["BASE_TABLE"]
    hist_table = cfg["HIST_TABLE"]
    key_cols = cfg["KEY_COLS"]
    entidad_label = cfg["ENTIDAD_LABEL"]
    baja_label = cfg["BAJA_LABEL"]

    print(f"\n[HIST] Procesando histórico para {base_table} -> {hist_table}")

    # Datos actuales desde la tabla base
    df_actual = cargar_df(conn, base_table)

    # Verificar si ya existe la tabla histórica
    existe_hist = False
    try:
        if hasattr(conn, "table_exists"):
            existe_hist = conn.table_exists(table=hist_table, schema=SCHEMA)
    except Exception as e:
        print(f"[{hist_table}] WARNING al verificar existencia de tabla: {e}")
        existe_hist = False

    if existe_hist:
        df_hist = cargar_df(conn, hist_table)
    else:
        df_hist = pd.DataFrame()

    # Detectar nuevas filas a insertar en la tabla histórica
    df_nuevos = detectar_cambios_generico(
        df_actual=df_actual,
        df_hist=df_hist,
        key_cols=key_cols,
        status_col=STATUS_COL,
        ignore_diff_cols=IGNORE_DIFF_COLS,
        entidad_label=entidad_label,
        baja_label=baja_label,
    )

    if df_nuevos.empty:
        print(f"[{hist_table}] Sin cambios; no se modifica la tabla histórica.")
        return

    # Unimos histórico existente con las nuevas versiones
    if df_hist.empty:
        df_hist_total = df_nuevos
    else:
        df_hist_total = pd.concat([df_hist, df_nuevos], ignore_index=True)

    # Recalcular ESTADO_REGISTRO en todo el histórico
    df_hist_total = recalcular_estados_generico(
        df_hist_total=df_hist_total,
        key_cols=key_cols,
        status_col=STATUS_COL,
    )

    # TRUNCATE + INSERT de la tabla histórica
    try:
        if existe_hist:
            conn.truncar_tabla(dataset_name=hist_table, schema=SCHEMA)
            print(f"[{hist_table}] TRUNCATE OK")
    except Exception as e:
        print(f"[{hist_table}] WARNING en TRUNCATE: {e}")

    conn.crea_tabla(df_hist_total, hist_table, if_exists="append")
    print(f"[{hist_table}] Insertados {len(df_hist_total)} registros en total.")


# ======================================================
# ORQUESTADOR
# ======================================================


def run() -> None:
    conn = sqlConn(predef_conn=PREDEF_CONN, agendado=False)

    try:
        for cfg in TABLAS_BOVEDA:
            procesar_tabla_boveda(conn, cfg)
    finally:
        try:
            conn.desconecta()
        except Exception:
            pass


if __name__ == "__main__":
    run()
