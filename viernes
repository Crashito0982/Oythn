import pandas as pd
from sqlConn import sqlConn

"""
Script de generación de histórico para las tablas del modelo de agencias.

Tablas base:
  - PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_DATOS
  - PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_PARAMETROS
  - PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_SEGURO

Tablas históricas:
  - PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_DATOS_HIST
  - PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_PARAMETROS_HIST
  - PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_SEGURO_HIST

Convención histórico:
  - La tabla HIST tiene todas las columnas de la tabla base
    + ESTADO_REGISTRO (VARCHAR(20))   -> 'VIGENTE' / 'ANTERIOR'
    + OBS_CAMBIO      (VARCHAR(255))  -> descripción del cambio
    + FECHA_CAMBIO    (DATETIME)      -> cuándo se generó esa versión

  - FECHA_CREACION viene de la tabla base (vuelco) y se ignora para comparar.

Lógica general:
  - Primera corrida: histórico vacío -> espejo completo de la tabla base
    con ESTADO_REGISTRO = 'VIGENTE' y OBS_CAMBIO = 'Carga inicial'.

  - Corridas siguientes:
      * Altas: claves nuevas que no existen en histórico -> VIGENTE
      * Cambios: misma clave lógica pero valores distintos -> nueva fila VIGENTE
      * Bajas: claves que existían y ya no están en base -> nueva fila ANTERIOR

  - Recalculo de ESTADO_REGISTRO:
      * Para cada clave lógica, se toma la(s) fila(s) con la mayor
        FECHA_REF (FECHA_CAMBIO o FECHA_CREACION).
      * Si la última versión es una baja, todas las filas de esa clave
        quedan ANTERIOR.
      * Si no es baja, la última versión queda VIGENTE y el resto ANTERIOR.

Notas:
  - Para PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_DATOS la clave lógica se asume
    AGENCIAS_TRANSPORTADORA (varchar), que representa AGENCIA + PROVEEDOR.
    Si por algún motivo viene NULL o falta, se deriva como "AGENCIA|PROVEEDOR".
"""

# ======================================================
# CONFIGURACIÓN GENERAL
# ======================================================

PREDEF_CONN = "AT_CMDTS"
SCHEMA = "dbo"

STATUS_COL = "ESTADO_REGISTRO"

# Columnas de la tabla base que se ignoran al comparar versiones
IGNORE_DIFF_COLS = {"FECHA_CREACION"}

TABLAS_AGENCIAS = [
    {
        "BASE_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_DATOS",
        "HIST_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_DATOS_HIST",
        "KEY_COLS": ["AGENCIAS_TRANSPORTADORA"],
        "ENTIDAD_LABEL": "dato de agencia/transportadora",
        "BAJA_LABEL": "dato ya no figura en la tabla base",
    },
    {
        "BASE_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_PARAMETROS",
        "HIST_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_PARAMETROS_HIST",
        "KEY_COLS": ["PARAMETROS"],
        "ENTIDAD_LABEL": "parámetro de agencia",
        "BAJA_LABEL": "parámetro ya no figura en la tabla base",
    },
    {
        "BASE_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_SEGURO",
        "HIST_TABLE": "PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_SEGURO_HIST",
        "KEY_COLS": ["COD_AG"],
        "ENTIDAD_LABEL": "seguro de agencia",
        "BAJA_LABEL": "seguro ya no figura en la tabla base",
    },
]


# ======================================================
# HELPERS
# ======================================================

def normalize_key_values(values):
    """Devuelve una tupla donde NaN/NaT se reemplazan por None."""
    out = []
    for v in values:
        out.append(None if pd.isna(v) else v)
    return tuple(out)


def cargar_df(conn: sqlConn, table_name: str) -> pd.DataFrame:
    return conn.descarga_tabla(nombre_base=table_name, schema=SCHEMA)


def ensure_agencias_transportadora(df: pd.DataFrame) -> pd.DataFrame:
    """Asegura que exista AGENCIAS_TRANSPORTADORA y que no venga todo NULL.

    Si falta o está NULL en algunas filas, deriva:
        AGENCIAS_TRANSPORTADORA = f"{AGENCIA}|{PROVEEDOR}"
    """
    if df.empty:
        return df

    if "AGENCIAS_TRANSPORTADORA" not in df.columns:
        df["AGENCIAS_TRANSPORTADORA"] = pd.NA

    needs_fill = df["AGENCIAS_TRANSPORTADORA"].isna()

    if needs_fill.any():
        if "AGENCIA" in df.columns and "PROVEEDOR" in df.columns:
            agencia = df["AGENCIA"].astype("string").fillna("")
            proveedor = df["PROVEEDOR"].astype("string").fillna("")
            derived = (agencia + "|" + proveedor).str.strip("|")
            df.loc[needs_fill, "AGENCIAS_TRANSPORTADORA"] = derived.loc[needs_fill]
    return df


def key_tuple_from_row(row: pd.Series, key_cols, suffix: str = ""):
    if len(key_cols) == 1:
        val = row.get(key_cols[0] + suffix, row.get(key_cols[0]))
        return None if pd.isna(val) else val

    vals = []
    for col in key_cols:
        val = row.get(col + suffix, row.get(col))
        vals.append(val)
    return normalize_key_values(vals)


def build_key_set(df: pd.DataFrame, key_cols):
    if df.empty:
        return set()

    if len(key_cols) == 1:
        return set(None if pd.isna(v) else v for v in df[key_cols[0]].tolist())

    res = set()
    for row in df[key_cols].itertuples(index=False, name=None):
        res.add(normalize_key_values(row))
    return res


def detectar_cambios_generico(
    df_actual: pd.DataFrame,
    df_hist: pd.DataFrame,
    key_cols,
    status_col: str,
    ignore_diff_cols=None,
    entidad_label: str = "registro",
    baja_label: str = "registro ya no figura en tabla base",
) -> pd.DataFrame:
    ignore_diff_cols = set(ignore_diff_cols or set())
    now_ts = pd.Timestamp.now()

    if df_hist.empty:
        df_nuevos = df_actual.copy()
        df_nuevos[status_col] = "VIGENTE"
        df_nuevos["OBS_CAMBIO"] = "Carga inicial"
        df_nuevos["FECHA_CAMBIO"] = now_ts
        return df_nuevos

    df_hist = df_hist.copy()

    # FECHA_REF para ordenar versiones
    df_hist["FECHA_REF"] = df_hist["FECHA_CAMBIO"] if "FECHA_CAMBIO" in df_hist.columns else pd.NaT
    if "FECHA_CREACION" in df_hist.columns:
        mask_ref = df_hist["FECHA_REF"].isna()
        df_hist.loc[mask_ref, "FECHA_REF"] = df_hist.loc[mask_ref, "FECHA_CREACION"]

    df_hist_sorted = df_hist.sort_values(list(key_cols) + ["FECHA_REF"])
    df_hist_ult = df_hist_sorted.groupby(list(key_cols), dropna=False).tail(1)

    merged = df_actual.merge(
        df_hist_ult,
        on=list(key_cols),
        how="left",
        suffixes=("_cur", "_prev"),
        indicator=True,
    )

    # Columnas de negocio a comparar
    cur_cols = [c for c in merged.columns if c.endswith("_cur")]
    base_cols = []
    for c in cur_cols:
        base_name = c[:-4]
        if base_name not in ignore_diff_cols and base_name not in {
            status_col,
            "OBS_CAMBIO",
            "FECHA_CAMBIO",
        }:
            base_cols.append(base_name)

    def columnas_cambiadas(row: pd.Series):
        cambios = []
        for col in base_cols:
            col_cur = f"{col}_cur"
            col_prev = f"{col}_prev"
            val_cur = row.get(col_cur, pd.NA)
            val_prev = row.get(col_prev, pd.NA)

            if pd.isna(val_cur) and pd.isna(val_prev):
                continue
            if (pd.isna(val_cur) and not pd.isna(val_prev)) or (not pd.isna(val_cur) and pd.isna(val_prev)):
                cambios.append(col)
            elif val_cur != val_prev:
                cambios.append(col)
        return cambios

    # IDs cuya última versión está dada de baja
    if "OBS_CAMBIO" in df_hist_ult.columns:
        mask_baja = df_hist_ult["OBS_CAMBIO"].fillna("").str.contains(
            r"^\s*Dado de baja\b", case=False, na=False, regex=True
        )
        if len(key_cols) == 1:
            ids_baja_hist = set(None if pd.isna(v) else v for v in df_hist_ult.loc[mask_baja, key_cols[0]].tolist())
        else:
            ids_baja_hist = set(
                normalize_key_values(row)
                for row in df_hist_ult.loc[mask_baja, key_cols].itertuples(index=False, name=None)
            )
    else:
        ids_baja_hist = set()

    ids_actual = build_key_set(df_actual, key_cols)
    ids_reactivados = ids_actual & ids_baja_hist

    def is_reactivacion(row: pd.Series) -> bool:
        if row["_merge"] != "both":
            return False
        key = key_tuple_from_row(row, key_cols, "")
        return key in ids_reactivados

    merged["ES_REACTIVACION"] = merged.apply(is_reactivacion, axis=1)

    filas_nuevas = []

    # Altas
    nuevos_ids = merged[merged["_merge"] == "left_only"]
    for _, row in nuevos_ids.iterrows():
        registro = {col: row.get(col, row.get(f"{col}_cur", pd.NA)) for col in df_actual.columns}
        registro[status_col] = "VIGENTE"
        registro["OBS_CAMBIO"] = f"Alta de {entidad_label} (nuevo ID)"
        registro["FECHA_CAMBIO"] = now_ts
        filas_nuevas.append(registro)

    # Reactivaciones
    reactivados = merged[merged["ES_REACTIVACION"]].copy()
    if not reactivados.empty:
        reactivados["CAMBIOS"] = reactivados.apply(columnas_cambiadas, axis=1)
        for _, row in reactivados.iterrows():
            registro = {col: row.get(col, row.get(f"{col}_cur", pd.NA)) for col in df_actual.columns}
            cols_cambiadas = row["CAMBIOS"]
            if cols_cambiadas:
                obs = (
                    f"Reactivación de {entidad_label} (estaba dado de baja). "
                    "Cambios en: " + ", ".join(cols_cambiadas)
                )
            else:
                obs = f"Reactivación de {entidad_label} (estaba dado de baja)"
            registro[status_col] = "VIGENTE"
            registro["OBS_CAMBIO"] = obs
            registro["FECHA_CAMBIO"] = now_ts
            filas_nuevas.append(registro)

    # Cambios normales
    coinciden = merged[(merged["_merge"] == "both") & (~merged["ES_REACTIVACION"])].copy()
    if not coinciden.empty:
        coinciden["CAMBIOS"] = coinciden.apply(columnas_cambiadas, axis=1)
        cambiados = coinciden[coinciden["CAMBIOS"].apply(len) > 0]
        for _, row in cambiados.iterrows():
            registro = {col: row.get(col, row.get(f"{col}_cur", pd.NA)) for col in df_actual.columns}
            registro[status_col] = "VIGENTE"
            registro["OBS_CAMBIO"] = "Cambios en: " + ", ".join(row["CAMBIOS"])
            registro["FECHA_CAMBIO"] = now_ts
            filas_nuevas.append(registro)

    # Bajas
    if len(key_cols) == 1:
        ids_hist = set(None if pd.isna(v) else v for v in df_hist_ult[key_cols[0]].tolist())
    else:
        ids_hist = set(
            normalize_key_values(row)
            for row in df_hist_ult[key_cols].itertuples(index=False, name=None)
        )

    ids_pot_baja = ids_hist - ids_actual

    if ids_pot_baja:
        df_baja_base = df_hist_ult.copy()
        df_baja_base["ES_BAJA"] = df_baja_base["OBS_CAMBIO"].fillna("").str.contains(
            r"^\s*Dado de baja\b", case=False, na=False, regex=True
        )

        def key_in_pot(row: pd.Series) -> bool:
            return key_tuple_from_row(row, key_cols, "") in ids_pot_baja

        df_baja_base = df_baja_base[df_baja_base.apply(key_in_pot, axis=1)]
        df_baja_nuevos = df_baja_base[~df_baja_base["ES_BAJA"]]

        for _, row in df_baja_nuevos.iterrows():
            registro = {col: row.get(col, pd.NA) for col in df_actual.columns}
            registro[status_col] = "ANTERIOR"
            registro["OBS_CAMBIO"] = f"Dado de baja ({baja_label})"
            registro["FECHA_CAMBIO"] = now_ts
            filas_nuevas.append(registro)

    if not filas_nuevas:
        return pd.DataFrame(columns=list(df_actual.columns) + [status_col, "OBS_CAMBIO", "FECHA_CAMBIO"])

    return pd.DataFrame(filas_nuevas)


def recalcular_estados_generico(
    df_hist_total: pd.DataFrame,
    key_cols,
    status_col: str,
) -> pd.DataFrame:
    df = df_hist_total.copy()

    df["FECHA_REF"] = df["FECHA_CAMBIO"] if "FECHA_CAMBIO" in df.columns else pd.NaT
    if "FECHA_CREACION" in df.columns:
        mask_ref = df["FECHA_REF"].isna()
        df.loc[mask_ref, "FECHA_REF"] = df.loc[mask_ref, "FECHA_CREACION"]

    df.sort_values(list(key_cols) + ["FECHA_REF"], inplace=True)

    df["MAX_FECHA_REF"] = df.groupby(list(key_cols), dropna=False)["FECHA_REF"].transform("max")
    df["ES_ULTIMA_VERSION"] = df["FECHA_REF"] == df["MAX_FECHA_REF"]

    # Clave normalizada para chequear bajas
    if len(key_cols) == 1:
        df["_KEY_"] = df[key_cols[0]].apply(lambda v: None if pd.isna(v) else v)
    else:
        df["_KEY_"] = [normalize_key_values(row) for row in df[key_cols].itertuples(index=False, name=None)]

    ultimas = df[df["ES_ULTIMA_VERSION"].copy()]
    ultimas["ES_BAJA"] = ultimas["OBS_CAMBIO"].fillna("").str.contains(
        r"^\s*Dado de baja\b", case=False, na=False, regex=True
    )
    ids_baja = set(ultimas.loc[ultimas["ES_BAJA"], "_KEY_"])

    df[status_col] = "ANTERIOR"
    mask_vig = df["ES_ULTIMA_VERSION"] & ~df["_KEY_"].isin(ids_baja)
    df.loc[mask_vig, status_col] = "VIGENTE"

    df.drop(columns=["FECHA_REF", "MAX_FECHA_REF", "ES_ULTIMA_VERSION", "_KEY_"], inplace=True)
    return df


# ======================================================
# PROCESO POR TABLA
# ======================================================

def procesar_tabla_agencias(conn: sqlConn, cfg: dict) -> None:
    base_table = cfg["BASE_TABLE"]
    hist_table = cfg["HIST_TABLE"]
    key_cols = cfg["KEY_COLS"]
    entidad_label = cfg["ENTIDAD_LABEL"]
    baja_label = cfg["BAJA_LABEL"]

    print(f"\n[HIST] Procesando histórico para {base_table} -> {hist_table}")

    df_actual = cargar_df(conn, base_table)

    # Caso especial: derivar/normalizar AGENCIAS_TRANSPORTADORA si aplica
    if base_table.upper() == "PLXS_BASE_PARAMETRICA_MODELO_AGENCIA_DATOS":
        df_actual = ensure_agencias_transportadora(df_actual)

    # Verificar si ya existe la tabla histórica
    existe_hist = False
    try:
        if hasattr(conn, "table_exists"):
            existe_hist = conn.table_exists(table=hist_table, schema=SCHEMA)
    except Exception as e:
        print(f"[{hist_table}] WARNING al verificar existencia de tabla: {e}")
        existe_hist = False

    df_hist = cargar_df(conn, hist_table) if existe_hist else pd.DataFrame()

    df_nuevos = detectar_cambios_generico(
        df_actual=df_actual,
        df_hist=df_hist,
        key_cols=key_cols,
        status_col=STATUS_COL,
        ignore_diff_cols=IGNORE_DIFF_COLS,
        entidad_label=entidad_label,
        baja_label=baja_label,
    )

    if df_nuevos.empty:
        print(f"[{hist_table}] Sin cambios; no se modifica la tabla histórica.")
        return

    df_hist_total = df_nuevos if df_hist.empty else pd.concat([df_hist, df_nuevos], ignore_index=True)

    df_hist_total = recalcular_estados_generico(
        df_hist_total=df_hist_total,
        key_cols=key_cols,
        status_col=STATUS_COL,
    )

    # TRUNCATE + INSERT
    try:
        if existe_hist:
            conn.truncar_tabla(dataset_name=hist_table, schema=SCHEMA)
            print(f"[{hist_table}] TRUNCATE OK")
    except Exception as e:
        print(f"[{hist_table}] WARNING en TRUNCATE: {e}")

    conn.crea_tabla(df_hist_total, hist_table, if_exists="append")
    print(f"[{hist_table}] Insertados {len(df_hist_total)} registros en total.")


# ======================================================
# ORQUESTADOR
# ======================================================

def run() -> None:
    conn = sqlConn(predef_conn=PREDEF_CONN, agendado=False)
    try:
        for cfg in TABLAS_AGENCIAS:
            procesar_tabla_agencias(conn, cfg)
    finally:
        try:
            conn.desconecta()
        except Exception:
            pass


if __name__ == "__main__":
    run()
