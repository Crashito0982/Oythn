import pandas as pd
from sqlConn import sqlConn

# === CONFIGURACIÓN BÁSICA ===
PREDEF_CONN = "ODSPE"
SCHEMA = "dbo"

BASE_TABLE = "PLXS_BASE_PARAMETRICA_MODELO_ATM"
HIST_TABLE = "PLXS_BASE_PARAMETRICA_MODELO_ATM_HIST"

# Clave lógica del ATM (ajustar si la clave real es compuesta)
KEY_COL = "ID"

# Columnas que NO disparan cambio funcional
# (se actualizan siempre por proceso, no porque cambie la parametría del ATM)
IGNORE_DIFF_COLS = {"INGRESADO", "FECHA_CIERRE", "FECHA CIERRE"}


# ==================== HELPERS ====================

def cargar_df(conn, table_name: str) -> pd.DataFrame:
    """
    Usa sqlConn.descarga_tabla para traer una tabla completa como DataFrame.
    OJO: el primer parámetro se llama 'nombre_base', no 'dataset_name'.
    """
    return conn.descarga_tabla(nombre_base=table_name, schema=SCHEMA)


def detectar_cambios(df_actual: pd.DataFrame, df_hist: pd.DataFrame) -> pd.DataFrame:
    """
    Construye el subconjunto de filas que deben agregarse a la tabla histórica.

    Casos:
      - Primera corrida (df_hist vacío): se copia todo df_actual como Carga inicial.
      - IDs nuevos: OBS_CAMBIO = 'Alta de ATM (nuevo ID)'.
      - IDs existentes con alguna columna distinta: OBS_CAMBIO = 'Cambios en: ...'.
      - IDs que estaban en histórico pero no están en la tabla actual:
            OBS_CAMBIO = 'Dado de baja (ATM ya no figura en tabla base)'.
    """
    now_ts = pd.Timestamp.now()

    # === 1) Primera corrida: histórico vacío -> espejo completo ===
    if df_hist.empty:
        df_nuevos = df_actual.copy()
        df_nuevos["ESTADO_ATM"] = "VIGENTE"
        df_nuevos["OBS_CAMBIO"] = "Carga inicial"
        df_nuevos["FECHA_CAMBIO"] = now_ts
        return df_nuevos

    df_hist = df_hist.copy()

    # --- Último registro histórico por ID ---
    if "FECHA_CAMBIO" in df_hist.columns:
        df_hist["FECHA_REF"] = df_hist["FECHA_CAMBIO"]
    else:
        df_hist["FECHA_REF"] = pd.NaT

    if "INGRESADO" in df_hist.columns:
        mask = df_hist["FECHA_REF"].isna()
        df_hist.loc[mask, "FECHA_REF"] = df_hist.loc[mask, "INGRESADO"]

    df_hist_sorted = df_hist.sort_values([KEY_COL, "FECHA_REF"])
    df_hist_ult = df_hist_sorted.groupby(KEY_COL, as_index=False).tail(1)

    # --- Merge tabla actual vs último histórico ---
    merged = df_actual.merge(
        df_hist_ult,
        on=KEY_COL,
        how="left",
        suffixes=("_cur", "_prev"),
        indicator=True,
    )

    # Columnas a comparar: todas menos la clave y las ignoradas
    base_cols = [
        c for c in df_actual.columns
        if c != KEY_COL and c not in IGNORE_DIFF_COLS
    ]

    def columnas_cambiadas(row):
        cambios = []
        for col in base_cols:
            val_cur = row.get(f"{col}_cur")
            val_prev = row.get(f"{col}_prev")

            # NaN == NaN => sin cambio
            if pd.isna(val_cur) and pd.isna(val_prev):
                continue

            if (pd.isna(val_cur) and not pd.isna(val_prev)) or \
               (not pd.isna(val_cur) and pd.isna(val_prev)) or \
               (val_cur != val_prev):
                cambios.append(col)
        return cambios

    filas_nuevas = []

    # === 2a) IDs nuevos (solo en tabla actual) ===
    nuevos_ids = merged[merged["_merge"] == "left_only"]
    for _, row in nuevos_ids.iterrows():
        registro = {}
        for col in df_actual.columns:
            registro[col] = row[f"{col}_cur"]
        registro["ESTADO_ATM"] = "VIGENTE"
        registro["OBS_CAMBIO"] = "Alta de ATM (nuevo ID)"
        registro["FECHA_CAMBIO"] = now_ts
        filas_nuevas.append(registro)

    # === 2b) IDs que ya existían: ver si alguna columna cambió ===
    coinciden = merged[merged["_merge"] == "both"].copy()
    coinciden["CAMBIOS"] = coinciden.apply(columnas_cambiadas, axis=1)

    cambiados = coinciden[coinciden["CAMBIOS"].apply(len) > 0]

    for _, row in cambiados.iterrows():
        registro = {}
        for col in df_actual.columns:
            registro[col] = row[f"{col}_cur"]

        cols_cambiadas = row["CAMBIOS"]
        obs = "Cambios en: " + ", ".join(cols_cambiadas)

        registro["ESTADO_ATM"] = "VIGENTE"   # luego se recalcula para todo el ID
        registro["OBS_CAMBIO"] = obs
        registro["FECHA_CAMBIO"] = now_ts
        filas_nuevas.append(registro)

    # === 2c) IDs que desaparecieron en la tabla base (baja de ATM) ===
    ids_hist = set(df_hist_ult[KEY_COL].unique())
    ids_actual = set(df_actual[KEY_COL].unique())
    ids_baja = ids_hist - ids_actual

    if ids_baja:
        df_baja_base = df_hist_ult[df_hist_ult[KEY_COL].isin(ids_baja)]
        for _, row in df_baja_base.iterrows():
            registro = {}
            # Copiamos los últimos valores conocidos de las columnas de negocio
            for col in df_actual.columns:
                registro[col] = row[col]
            registro["ESTADO_ATM"] = "ANTERIOR"
            registro["OBS_CAMBIO"] = "Dado de baja (ATM ya no figura en tabla base)"
            registro["FECHA_CAMBIO"] = now_ts
            filas_nuevas.append(registro)

    if not filas_nuevas:
        # No hay nada que agregar al histórico hoy
        return pd.DataFrame(
            columns=list(df_actual.columns) +
                    ["ESTADO_ATM", "OBS_CAMBIO", "FECHA_CAMBIO"]
        )

    return pd.DataFrame(filas_nuevas)


def recalcular_estados(df_hist_total: pd.DataFrame) -> pd.DataFrame:
    """
    A partir del histórico completo (viejos + nuevos), recalcula ESTADO_ATM.

    Regla:
      - Para cada ID, se mira el último registro (por FECHA_CAMBIO o INGRESADO).
      - Si el último registro tiene OBS_CAMBIO que contiene 'Dado de baja':
            -> TODOS los registros de ese ID quedan como 'ANTERIOR'
               (no hay versión vigente).
      - En caso contrario:
            -> El último registro queda 'VIGENTE'
            -> Los anteriores quedan 'ANTERIOR'
    """
    df = df_hist_total.copy()

    if "FECHA_CAMBIO" in df.columns:
        df["FECHA_REF"] = df["FECHA_CAMBIO"]
    else:
        df["FECHA_REF"] = pd.NaT

    if "INGRESADO" in df.columns:
        mask = df["FECHA_REF"].isna()
        df.loc[mask, "FECHA_REF"] = df.loc[mask, "INGRESADO"]

    df.sort_values([KEY_COL, "FECHA_REF"], inplace=True)

    df["ESTADO_ATM"] = "ANTERIOR"
    idx_ultimos = df.groupby(KEY_COL)["FECHA_REF"].idxmax()

    # Último registro por ID
    ultimos = df.loc[idx_ultimos, [KEY_COL, "OBS_CAMBIO"]].copy()
    ultimos["ES_BAJA"] = ultimos["OBS_CAMBIO"].fillna("").str.contains(
        "Dado de baja", case=False, na=False
    )

    ids_baja = set(ultimos[ultimos["ES_BAJA"]][KEY_COL].unique())

    # IDs que NO están dados de baja → último registro = VIGENTE
    idx_vigentes = [
        idx for idx in idx_ultimos
        if df.at[idx, KEY_COL] not in ids_baja
    ]
    df.loc[idx_vigentes, "ESTADO_ATM"] = "VIGENTE"

    df.drop(columns=["FECHA_REF"], inplace=True)
    return df


# ==================== SCRIPT PRINCIPAL ====================

def run():
    """
    Script histórico para PLXS_BASE_PARAMETRICA_MODELO_ATM_HIST.
    Pensado para ejecutarse después del vuelco diario de la tabla base.
    """
    conn = sqlConn(predef_conn=PREDEF_CONN, agendado=False)

    try:
        # 1) Tabla actual (paramétrica diaria)
        df_actual = cargar_df(conn, BASE_TABLE)

        # 2) Tabla histórica (si existe)
        try:
            if hasattr(conn, "table_exists") and conn.table_exists(
                dataset_name=HIST_TABLE, schema=SCHEMA
            ):
                df_hist = cargar_df(conn, HIST_TABLE)
            else:
                df_hist = pd.DataFrame()
        except Exception:
            # Si hay error al consultar la tabla, asumimos que está vacía
            df_hist = pd.DataFrame()

        # 3) Ver qué filas nuevas hay que agregar al histórico
        df_nuevos = detectar_cambios(df_actual, df_hist)

        if df_nuevos.empty:
            print("[HIST] Sin cambios; no se modifica PLXS_BASE_PARAMETRICA_MODELO_ATM_HIST.")
            return

        # 4) Concatenar histórico viejo + nuevos
        if df_hist.empty:
            df_hist_total = df_nuevos
        else:
            df_hist_total = pd.concat([df_hist, df_nuevos], ignore_index=True)

        # 5) Recalcular ESTADO_ATM por ID
        df_hist_total = recalcular_estados(df_hist_total)

        # 6) TRUNCATE + INSERT (porque en ODSPE no se quieren UPDATEs)
        try:
            if hasattr(conn, "table_exists") and conn.table_exists(
                dataset_name=HIST_TABLE, schema=SCHEMA
            ):
                conn.truncar_tabla(dataset_name=HIST_TABLE, schema=SCHEMA)
                print(f"[{HIST_TABLE}] TRUNCATE OK")
        except Exception as e:
            print(f"[{HIST_TABLE}] WARNING en TRUNCATE: {e}")

        # crea_tabla debería crear la tabla si no existe
        conn.crea_tabla(df_hist_total, HIST_TABLE, if_exists="append")
        print(f"[{HIST_TABLE}] Insertados {len(df_hist_total)} registros en total.")

    finally:
        try:
            conn.desconecta()
        except Exception:
            pass


if __name__ == "__main__":
    run()
